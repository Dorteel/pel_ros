{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes:\n",
    "Does not work well.\n",
    "I need to try blurring the image so the high level features stay."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run Yolo on input images, save detected objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/mark/.cache/torch/hub/ultralytics_yolov5_master\n",
      "YOLOv5 ðŸš€ 2024-7-25 Python-3.8.10 torch-2.3.1+cu121 CPU\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\n",
      "Adding AutoShape... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected and saved 1 cropped images of chair from input_imgs/office-chair-2.png.\n",
      "Detected and saved 5 cropped images of chair from input_imgs/dining-chair-2.png.\n",
      "Detected and saved 2 cropped images of chair from input_imgs/office-chair-1.png.\n",
      "Detected and saved 1 cropped images of chair from input_imgs/dining-chair-1.png.\n",
      "Detected and saved 0 cropped images of chair from input_imgs/arm-chair-1.png.\n",
      "Detected and saved 2 cropped images of chair from input_imgs/arm-chair-2.png.\n",
      "Total detected and saved images: 11\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from PIL import Image, UnidentifiedImageError\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the YOLOv5 model\n",
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5s')  # You can change 'yolov5s' to any other YOLOv5 model\n",
    "\n",
    "def detect_and_crop(image_path, output_path, target_obj):\n",
    "    # Load image\n",
    "    try:\n",
    "        img = cv2.imread(image_path)\n",
    "        # You may need to convert the color.\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = Image.fromarray(img)\n",
    "        #img = Image.open(image_path).convert(\"RGB\")  # Ensure the image is in RGB format\n",
    "        img_np = np.array(img)\n",
    "    except UnidentifiedImageError:\n",
    "        print(f\"Skipping invalid image file: {image_path}\")\n",
    "        return 0\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file {image_path}: {e}\")\n",
    "        return 0\n",
    "    \n",
    "    # Perform inference\n",
    "    results = model(img_np)\n",
    "\n",
    "    # Extract bounding boxes\n",
    "    detections = results.xyxy[0].numpy()  # x1, y1, x2, y2, confidence, class\n",
    "    names = results.names  # Class names\n",
    "    count = 0\n",
    "    for i, detection in enumerate(detections):\n",
    "        x1, y1, x2, y2, conf, cls = map(int, detection[:6])\n",
    "        \n",
    "        # Crop the bounding box from the original image\n",
    "        if names[cls] == target_obj:\n",
    "            cropped_img = img_np[y1:y2, x1:x2]\n",
    "            cropped_pil_img = Image.fromarray(cropped_img)\n",
    "            # os.makedirs(output_path, exist_ok=True)\n",
    "            cropped_pil_img.save(f\"{output_path}_{names[cls]}_crop_{i}.png\")\n",
    "            count += 1\n",
    "\n",
    "    print(f\"Detected and saved {count} cropped images of {target_obj} from {image_path}.\")\n",
    "    return count\n",
    "\n",
    "# Example usage\n",
    "img = 'dining-chair-1'\n",
    "total_detected = 0\n",
    "# cropping_path = 'wikidata_imgs/raw'\n",
    "# output_path = 'wikidata_imgs/cropped/'\n",
    "cropping_path = 'input_imgs/'\n",
    "output_path = 'cropped_imgs/'\n",
    "for root, dirs, files in os.walk(cropping_path):\n",
    "    for file in files:\n",
    "        file_path = os.path.join(root, file)\n",
    "        filename = file.split('.')[-2]\n",
    "        #print(f\"Processing file: {file}\")\n",
    "        detected = detect_and_crop(file_path, f\"{output_path}{filename}\", 'chair')\n",
    "        total_detected += detected\n",
    "\n",
    "print(f\"Total detected and saved images: {total_detected}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Take detected objects, run similarity matching on wikidata imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: cropped_imgs/dining-chair-2_chair_crop_11.png\n",
      "...Matching dining-chair-2_chair_crop_11\n",
      "Processing file: cropped_imgs/office-chair-2_chair_crop_0.png\n",
      "...Matching office-chair-2_chair_crop_0\n",
      "Processing file: cropped_imgs/arm-chair-2_chair_crop_6.png\n",
      "...Matching arm-chair-2_chair_crop_6\n",
      "Processing file: cropped_imgs/dining-chair-2_chair_crop_0.png\n",
      "...Matching dining-chair-2_chair_crop_0\n",
      "Processing file: cropped_imgs/dining-chair-2_chair_crop_3.png\n",
      "...Matching dining-chair-2_chair_crop_3\n",
      "Processing file: cropped_imgs/arm-chair-2_chair_crop_0.png\n",
      "...Matching arm-chair-2_chair_crop_0\n",
      "Processing file: cropped_imgs/office-chair-1_chair_crop_0.png\n",
      "...Matching office-chair-1_chair_crop_0\n",
      "Processing file: cropped_imgs/dining-chair-1_chair_crop_1.png\n",
      "...Matching dining-chair-1_chair_crop_1\n",
      "Processing file: cropped_imgs/office-chair-1_chair_crop_1.png\n",
      "...Matching office-chair-1_chair_crop_1\n",
      "Processing file: cropped_imgs/dining-chair-2_chair_crop_1.png\n",
      "...Matching dining-chair-2_chair_crop_1\n",
      "Processing file: cropped_imgs/dining-chair-2_chair_crop_10.png\n",
      "...Matching dining-chair-2_chair_crop_10\n"
     ]
    }
   ],
   "source": [
    "def match_detections(cropped_imgs_folder, wikidata_imgs_folder, output_folder):\n",
    "    # Initialize SIFT detector\n",
    "    sift = cv2.SIFT_create()\n",
    "    file_name = cropped_imgs_folder.split('/')[-1].split('.')[-2]\n",
    "    print(f'...Matching {file_name}')\n",
    "    # Function to read images and convert to grayscale\n",
    "    def read_image(image_path):\n",
    "        img = cv2.imread(image_path)\n",
    "        return cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Load all cropped images\n",
    "    cropped_images = []\n",
    "    for root, _, files in os.walk(cropped_imgs_folder):\n",
    "        for file in files:\n",
    "            cropped_images.append((os.path.join(root, file), read_image(os.path.join(root, file))))\n",
    "\n",
    "    # Load all wikidata images\n",
    "    wikidata_images = []\n",
    "    for root, _, files in os.walk(wikidata_imgs_folder):\n",
    "        for file in files:\n",
    "            wikidata_images.append((os.path.join(root, file), read_image(os.path.join(root, file))))\n",
    "\n",
    "    best_match = None\n",
    "    highest_score = 0\n",
    "    \n",
    "    # Match each cropped image with each wikidata image\n",
    "    for cropped_path, cropped_img in cropped_images:\n",
    "        kp1, des1 = sift.detectAndCompute(cropped_img, None)\n",
    "        for wikidata_path, wikidata_img in wikidata_images:\n",
    "            kp2, des2 = sift.detectAndCompute(wikidata_img, None)\n",
    "            \n",
    "            # Use BFMatcher to find matches\n",
    "            bf = cv2.BFMatcher()\n",
    "            matches = bf.knnMatch(des1, des2, k=2)\n",
    "            \n",
    "            # Apply ratio test\n",
    "            good_matches = []\n",
    "            for m, n in matches:\n",
    "                if m.distance < 0.75 * n.distance:\n",
    "                    good_matches.append(m)\n",
    "            \n",
    "            if len(good_matches) > highest_score:\n",
    "                highest_score = len(good_matches)\n",
    "                best_match = (cropped_path, wikidata_path, kp1, kp2, good_matches, cropped_img, wikidata_img)\n",
    "\n",
    "    if best_match:\n",
    "        cropped_path, wikidata_path, kp1, kp2, good_matches, cropped_img, wikidata_img = best_match\n",
    "        print(f\"Best match: {cropped_path} and {wikidata_path} with {highest_score} matches.\")\n",
    "        \n",
    "        # Draw matches\n",
    "        matched_img = cv2.drawMatches(cropped_img, kp1, wikidata_img, kp2, good_matches, None, flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "        \n",
    "        # Save the image with matched features\n",
    "        os.makedirs(output_folder, exist_ok=True)\n",
    "        matched_img_path = os.path.join(output_folder, f'{file_name}.png')\n",
    "        cv2.imwrite(matched_img_path, matched_img)\n",
    "        print(f\"Matched image saved at {matched_img_path}\")\n",
    "\n",
    "matching_path = 'cropped_imgs/'\n",
    "\n",
    "for root, dirs, files in os.walk(matching_path):\n",
    "    for file in files:\n",
    "        file_path = os.path.join(root, file)\n",
    "        filename = file.split('.')[-2]\n",
    "        print(f\"Processing file: {file_path}\")\n",
    "        match_detections(f'{file_path}', 'wikidata_imgs/cropped/', 'matched_imgs/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: cropped_imgs/dining-chair-2_chair_crop_11.png\n",
      "Best match: cropped_imgs/dining-chair-2_chair_crop_11.png and wikidata_imgs/cropped/commons-image-office-chair-1chair_crop_1.png with 11 matches.\n",
      "Matched image saved at matched_imgs/dining-chair-2_chair_crop_11_match.png\n",
      "Processing file: cropped_imgs/office-chair-2_chair_crop_0.png\n",
      "Best match: cropped_imgs/office-chair-2_chair_crop_0.png and wikidata_imgs/cropped/commons-image-office-chair-1chair_crop_1.png with 26 matches.\n",
      "Matched image saved at matched_imgs/office-chair-2_chair_crop_0_match.png\n",
      "Processing file: cropped_imgs/arm-chair-2_chair_crop_6.png\n",
      "Processing file: cropped_imgs/dining-chair-2_chair_crop_0.png\n",
      "Best match: cropped_imgs/dining-chair-2_chair_crop_0.png and wikidata_imgs/cropped/commons-image-office-chair-1chair_crop_3.png with 1 matches.\n",
      "Matched image saved at matched_imgs/dining-chair-2_chair_crop_0_match.png\n",
      "Processing file: cropped_imgs/dining-chair-2_chair_crop_3.png\n",
      "Best match: cropped_imgs/dining-chair-2_chair_crop_3.png and wikidata_imgs/cropped/commons-image-office-chair-1chair_crop_1.png with 4 matches.\n",
      "Matched image saved at matched_imgs/dining-chair-2_chair_crop_3_match.png\n",
      "Processing file: cropped_imgs/arm-chair-2_chair_crop_0.png\n",
      "Best match: cropped_imgs/arm-chair-2_chair_crop_0.png and wikidata_imgs/cropped/commons-image-office-chair-1chair_crop_3.png with 1 matches.\n",
      "Matched image saved at matched_imgs/arm-chair-2_chair_crop_0_match.png\n",
      "Processing file: cropped_imgs/office-chair-1_chair_crop_0.png\n",
      "Best match: cropped_imgs/office-chair-1_chair_crop_0.png and wikidata_imgs/cropped/commons-image-office-chair-1chair_crop_1.png with 34 matches.\n",
      "Matched image saved at matched_imgs/office-chair-1_chair_crop_0_match.png\n",
      "Processing file: cropped_imgs/dining-chair-1_chair_crop_1.png\n",
      "Best match: cropped_imgs/dining-chair-1_chair_crop_1.png and wikidata_imgs/cropped/commons-image-office-chair-1chair_crop_1.png with 36 matches.\n",
      "Matched image saved at matched_imgs/dining-chair-1_chair_crop_1_match.png\n",
      "Processing file: cropped_imgs/office-chair-1_chair_crop_1.png\n",
      "Best match: cropped_imgs/office-chair-1_chair_crop_1.png and wikidata_imgs/cropped/commons-image-office-chair-1chair_crop_1.png with 14 matches.\n",
      "Matched image saved at matched_imgs/office-chair-1_chair_crop_1_match.png\n",
      "Processing file: cropped_imgs/dining-chair-2_chair_crop_1.png\n",
      "Processing file: cropped_imgs/dining-chair-2_chair_crop_10.png\n",
      "Best match: cropped_imgs/dining-chair-2_chair_crop_10.png and wikidata_imgs/cropped/commons-image-chair-2chair_crop_0.png with 1 matches.\n",
      "Matched image saved at matched_imgs/dining-chair-2_chair_crop_10_match.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image, UnidentifiedImageError\n",
    "\n",
    "# Function to read an image and convert to grayscale\n",
    "def read_image(image_path):\n",
    "    img = cv2.imread(image_path)\n",
    "    return cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Function to find the best match for a given image\n",
    "def find_best_match(file_path, wikidata_imgs_folder, output_folder):\n",
    "    # Initialize SIFT detector\n",
    "    sift = cv2.SIFT_create()\n",
    "\n",
    "    # Read the input image\n",
    "    try:\n",
    "        input_img = read_image(file_path)\n",
    "        kp1, des1 = sift.detectAndCompute(input_img, None)\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading input image {file_path}: {e}\")\n",
    "        return\n",
    "\n",
    "    # Load all wikidata images\n",
    "    wikidata_images = []\n",
    "    for root, _, files in os.walk(wikidata_imgs_folder):\n",
    "        for file in files:\n",
    "            wikidata_images.append((os.path.join(root, file), read_image(os.path.join(root, file))))\n",
    "\n",
    "    best_match = None\n",
    "    highest_score = 0\n",
    "\n",
    "    # Match the input image with each wikidata image\n",
    "    for wikidata_path, wikidata_img in wikidata_images:\n",
    "        kp2, des2 = sift.detectAndCompute(wikidata_img, None)\n",
    "\n",
    "        # Use BFMatcher to find matches\n",
    "        bf = cv2.BFMatcher()\n",
    "        matches = bf.knnMatch(des1, des2, k=2)\n",
    "\n",
    "        # Apply ratio test\n",
    "        good_matches = []\n",
    "        for m, n in matches:\n",
    "            if m.distance < 0.75 * n.distance:\n",
    "                good_matches.append(m)\n",
    "\n",
    "        if len(good_matches) > highest_score:\n",
    "            highest_score = len(good_matches)\n",
    "            best_match = (wikidata_path, kp1, kp2, good_matches, input_img, wikidata_img)\n",
    "\n",
    "    if best_match:\n",
    "        wikidata_path, kp1, kp2, good_matches, input_img, wikidata_img = best_match\n",
    "        print(f\"Best match: {file_path} and {wikidata_path} with {highest_score} matches.\")\n",
    "\n",
    "        # Draw matches\n",
    "        matched_img = cv2.drawMatches(input_img, kp1, wikidata_img, kp2, good_matches, None, flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "\n",
    "        # Save the image with matched features\n",
    "        os.makedirs(output_folder, exist_ok=True)\n",
    "        matched_img_path = os.path.join(output_folder, os.path.basename(file_path).split('.')[0] + '_match.png')\n",
    "        cv2.imwrite(matched_img_path, matched_img)\n",
    "        print(f\"Matched image saved at {matched_img_path}\")\n",
    "\n",
    "\n",
    "for root, dirs, files in os.walk(matching_path):\n",
    "    for file in files:\n",
    "        file_path = os.path.join(root, file)\n",
    "        filename = file.split('.')[-2]\n",
    "        print(f\"Processing file: {file_path}\")\n",
    "        find_best_match(file_path, 'wikidata_imgs/cropped/', 'matched_imgs/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: cropped_imgs/dining-chair-2_chair_crop_11.png\n",
      "Best match: cropped_imgs/dining-chair-2_chair_crop_11.png and wikidata_imgs/cropped/commons-image-chair-2chair_crop_0.png with 9 matches.\n",
      "Matched image saved at matched_imgs/dining-chair-2_chair_crop_11_match.png\n",
      "Processing file: cropped_imgs/office-chair-2_chair_crop_0.png\n",
      "Best match: cropped_imgs/office-chair-2_chair_crop_0.png and wikidata_imgs/cropped/commons-image-chair-2chair_crop_1.png with 12 matches.\n",
      "Matched image saved at matched_imgs/office-chair-2_chair_crop_0_match.png\n",
      "Processing file: cropped_imgs/arm-chair-2_chair_crop_6.png\n",
      "Best match: cropped_imgs/arm-chair-2_chair_crop_6.png and wikidata_imgs/cropped/commons-image-office-chair-1chair_crop_0.png with 2 matches.\n",
      "Matched image saved at matched_imgs/arm-chair-2_chair_crop_6_match.png\n",
      "Processing file: cropped_imgs/dining-chair-2_chair_crop_0.png\n",
      "Processing file: cropped_imgs/dining-chair-2_chair_crop_3.png\n",
      "Processing file: cropped_imgs/arm-chair-2_chair_crop_0.png\n",
      "Processing file: cropped_imgs/office-chair-1_chair_crop_0.png\n",
      "Best match: cropped_imgs/office-chair-1_chair_crop_0.png and wikidata_imgs/cropped/commons-image-chair-2chair_crop_0.png with 11 matches.\n",
      "Matched image saved at matched_imgs/office-chair-1_chair_crop_0_match.png\n",
      "Processing file: cropped_imgs/dining-chair-1_chair_crop_1.png\n",
      "Best match: cropped_imgs/dining-chair-1_chair_crop_1.png and wikidata_imgs/cropped/commons-image-chair-2chair_crop_0.png with 4 matches.\n",
      "Matched image saved at matched_imgs/dining-chair-1_chair_crop_1_match.png\n",
      "Processing file: cropped_imgs/office-chair-1_chair_crop_1.png\n",
      "Best match: cropped_imgs/office-chair-1_chair_crop_1.png and wikidata_imgs/cropped/commons-image-chair-3chair_crop_0.png with 1 matches.\n",
      "Matched image saved at matched_imgs/office-chair-1_chair_crop_1_match.png\n",
      "Processing file: cropped_imgs/dining-chair-2_chair_crop_1.png\n",
      "Processing file: cropped_imgs/dining-chair-2_chair_crop_10.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image, UnidentifiedImageError\n",
    "\n",
    "# Function to read an image and convert to grayscale\n",
    "def read_image(image_path):\n",
    "    img = cv2.imread(image_path)\n",
    "    return cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Function to find the best match for a given image\n",
    "def find_best_match(file_path, wikidata_imgs_folder, output_folder):\n",
    "    # Initialize ORB detector\n",
    "    orb = cv2.ORB_create()\n",
    "\n",
    "    # Read the input image\n",
    "    try:\n",
    "        input_img = read_image(file_path)\n",
    "        kp1, des1 = orb.detectAndCompute(input_img, None)\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading input image {file_path}: {e}\")\n",
    "        return\n",
    "\n",
    "    # Load all wikidata images\n",
    "    wikidata_images = []\n",
    "    for root, _, files in os.walk(wikidata_imgs_folder):\n",
    "        for file in files:\n",
    "            wikidata_images.append((os.path.join(root, file), read_image(os.path.join(root, file))))\n",
    "\n",
    "    best_match = None\n",
    "    highest_score = 0\n",
    "\n",
    "    # FLANN parameters\n",
    "    FLANN_INDEX_LSH = 6\n",
    "    index_params = dict(algorithm=FLANN_INDEX_LSH, table_number=6, key_size=12, multi_probe_level=1)\n",
    "    search_params = dict(checks=50)\n",
    "    flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "\n",
    "    # Match the input image with each wikidata image\n",
    "    for wikidata_path, wikidata_img in wikidata_images:\n",
    "        kp2, des2 = orb.detectAndCompute(wikidata_img, None)\n",
    "\n",
    "        # Use FLANN matcher to find matches\n",
    "        matches = flann.knnMatch(des1, des2, k=2)\n",
    "\n",
    "        # Apply ratio test\n",
    "        good_matches = []\n",
    "        for match in matches:\n",
    "            if len(match) == 2:\n",
    "                m, n = match\n",
    "                if m.distance < 0.75 * n.distance:\n",
    "                    good_matches.append(m)\n",
    "\n",
    "        if len(good_matches) > highest_score:\n",
    "            highest_score = len(good_matches)\n",
    "            best_match = (wikidata_path, kp1, kp2, good_matches, input_img, wikidata_img)\n",
    "\n",
    "    if best_match:\n",
    "        wikidata_path, kp1, kp2, good_matches, input_img, wikidata_img = best_match\n",
    "        print(f\"Best match: {file_path} and {wikidata_path} with {highest_score} matches.\")\n",
    "\n",
    "        # Draw matches\n",
    "        matched_img = cv2.drawMatches(input_img, kp1, wikidata_img, kp2, good_matches, None, flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "\n",
    "        # Save the image with matched features\n",
    "        os.makedirs(output_folder, exist_ok=True)\n",
    "        matched_img_path = os.path.join(output_folder, os.path.basename(file_path).split('.')[0] + '_match.png')\n",
    "        cv2.imwrite(matched_img_path, matched_img)\n",
    "        print(f\"Matched image saved at {matched_img_path}\")\n",
    "\n",
    "\n",
    "for root, dirs, files in os.walk(matching_path):\n",
    "    for file in files:\n",
    "        file_path = os.path.join(root, file)\n",
    "        filename = file.split('.')[-2]\n",
    "        print(f\"Processing file: {file_path}\")\n",
    "        find_best_match(file_path, 'wikidata_imgs/cropped/', 'matched_imgs/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ros-default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
